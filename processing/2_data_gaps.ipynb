{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify balloon maneuvering and create data segments\n",
    "\n",
    "Author: Brian Green (briangre@stanford.edu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from notebook_utils import before_and_after_flights\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy import interpolate\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    tqdm.pandas()\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "RMEAN_LENG = 61                           # the number of values used in the running mean (should be odd, because \n",
    "                                          # it's centered)\n",
    "VERTVEL_THRESH_DT = pd.Timedelta(4, 'hours')  # the time it takes the smoothed (running mean) altitude to change\n",
    "                                          # DZ_THRESH; less time means the balloon is suspected of taking \n",
    "                                          # off/landing/depressurizing\n",
    "DZ_THRESH = 1000                          # (meters); any continuous segments violating VERTVEL_THRESH over a\n",
    "                                          # height range greater than DZ_THRESH will be deleted\n",
    "MIN_SEG_LEN = pd.Timedelta(1, 'hours')    # the minimum segment length\n",
    "SEG_MIN_ALT = 10000                       # (meters); the minimum segment mean altitude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data from the previous step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights = pd.read_feather('temp_data/1_flights_sorted.feather')\n",
    "n_data_orig = flights.shape[0]\n",
    "\n",
    "## Sometimes the COSMIC code struggles to analyze all the years at once; when that happens,\n",
    "## process one year at a time\n",
    "## Select just the flights in 2014\n",
    "#flight_time_start = flights.groupby('flight_id').progress_apply(lambda f: f.time.iloc[0])\n",
    "#flight_ids = flight_time_start[flight_time_start < pd.Timestamp('2014-12-01 00:00:00')]\n",
    "#flight_ids = flight_ids[flight_ids >= pd.Timestamp('2014-07-01 00:00:00')]\n",
    "#flights = flights[flights.flight_id.isin(flight_ids.index)]\n",
    "#n_data_orig = flights.shape[0]\n",
    "#flights_temp.flight_id.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split up the flights into segments when the balloon's maneuvering system is turned on (ACS or propeller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating flight length:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb4ff86cbe4f4cc7b66b81d0cd47e175",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0/7 flights that are too short\n",
      " \n",
      "Splitting the flights into segments:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6dc9935c365438b88f3643bf597df00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of segments: 11634\n",
      " \n",
      "Calculating segment length:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8c7dfef5d814f889d30ecb29693c523",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11634 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 9262/11634 segments that are too short\n",
      " \n"
     ]
    }
   ],
   "source": [
    "def segments_from_maneuvering(flight):\n",
    "    \n",
    "    # Create a counter so that the segment ID is incremented across the flights, creating unique segment IDs\n",
    "    if \"counter\" not in segments_from_maneuvering.__dict__:\n",
    "        segments_from_maneuvering.counter = 0\n",
    "        \n",
    "    # Each time maneuvering stops, a new segment begins:\n",
    "    flight['segment_id'] = (flight.maneuvering.diff() == -1).astype(int).cumsum()\n",
    "    n_segments = flight.segment_id.max() + 1 # the segments start at zero\n",
    "    \n",
    "    # Delete any data points where maneuvering is happening\n",
    "    flight = flight[flight.maneuvering==0]\n",
    "    \n",
    "    # Apply the counter and increment it\n",
    "    flight.segment_id = flight.segment_id + segments_from_maneuvering.counter\n",
    "    segments_from_maneuvering.counter = segments_from_maneuvering.counter + n_segments\n",
    "    \n",
    "    return flight\n",
    "\n",
    "# Delete flights that are too short\n",
    "print('Calculating flight length:')\n",
    "num_before = flights.flight_id.nunique()\n",
    "flight_length = flights.groupby('flight_id').progress_apply(lambda f: f.time.iloc[-1] - f.time.iloc[0])\n",
    "flights_tooshort = flight_length[flight_length < MIN_SEG_LEN]\n",
    "flights = flights[~flights.flight_id.isin(flights_tooshort.index)].reset_index(drop=True)\n",
    "print(f'Removed {num_before-flights.flight_id.nunique()}/{num_before} flights that are too short')\n",
    "print(' ')\n",
    "\n",
    "# Combine the acs and propeller_on columns into one variable that indicates if the balloon is maneuvering\n",
    "flights['maneuvering'] = 0\n",
    "flights.loc[flights.acs > 0, 'maneuvering'] = 1\n",
    "flights.loc[flights.propeller_on > 0, 'maneuvering'] = 1\n",
    "flights = flights.drop(columns=['acs','propeller_on'])\n",
    "\n",
    "# Split flights into segments where maneuvering is zero\n",
    "print('Splitting the flights into segments:')\n",
    "flights = flights.groupby('flight_id').progress_apply(segments_from_maneuvering).reset_index(drop=True)\n",
    "print(f'Number of segments: {flights.segment_id.nunique()}')\n",
    "print(' ')\n",
    "\n",
    "# Delete segments that are too short\n",
    "print('Calculating segment length:')\n",
    "num_before = flights.segment_id.nunique()\n",
    "segment_length = flights.groupby('segment_id').progress_apply(lambda f: f.time.iloc[-1] - f.time.iloc[0])\n",
    "segments_tooshort = segment_length[segment_length < MIN_SEG_LEN]\n",
    "flights = flights[~flights.segment_id.isin(segments_tooshort.index)].reset_index(drop=True)\n",
    "print(f'Removed {num_before-flights.segment_id.nunique()}/{num_before} segments that are too short')\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look for times when the balloon might have deviated from isopycnic behavior (takeoffs/landings, depressurizations, etc.)\n",
    "\n",
    "This is done by calculating the running mean altitude, then looking for instances when it changed rapidly enough to be flagged as suspicious."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating segment length:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0420b3980e4a40788c09d6889219b918",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2372 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 715/2372 segments that are too short\n",
      " \n",
      "Calculating smoothed altitude and vertical velocity:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36fa8fb7d6144efcb75f3bd79c0b1d6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1657 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def altitude_runningmean(segment):\n",
    "    \n",
    "    # Calculate the running mean of the altitude\n",
    "    temp = np.array(segment.altitude)\n",
    "    rmean = np.zeros(np.size(temp))\n",
    "    ind = int(np.floor(RMEAN_LENG/2))\n",
    "    # calculate the running mean in the middle of the time series\n",
    "    for i in np.arange(RMEAN_LENG-1):\n",
    "        rmean[ind:-ind] = rmean[ind:-ind]+temp[i:-(RMEAN_LENG-i-1)]/RMEAN_LENG\n",
    "    rmean[ind:-ind] = rmean[ind:-ind]+temp[RMEAN_LENG-1:]/RMEAN_LENG\n",
    "    # calculate the running mean at the time series edges\n",
    "    for i in np.arange(ind):\n",
    "        rmean[i] = np.mean(temp[:ind+i])\n",
    "        rmean[-(i+1)] = np.mean(temp[-(ind+i):])\n",
    "    segment['alt_rmean'] = rmean\n",
    "    \n",
    "    # Calculate the vertical velocity using the running mean\n",
    "    # The time steps are uneven, so I'm doing a weighted centered difference\n",
    "    dt = np.array(segment.time.diff()/pd.Timedelta(1,'seconds'))\n",
    "    dz = np.array(segment['alt_rmean'].diff())\n",
    "    dt1 = dt[1:-1]\n",
    "    dt2 = dt[2:]\n",
    "    w1 = dz[1:-1]/dt1\n",
    "    w2 = dz[2:]/dt2\n",
    "    w = (w1*dt2 + w2*dt1)/(dt1 + dt2)\n",
    "    segment['w_smooth'] = np.nan\n",
    "    segment.w_smooth.iloc[1:-1] = w\n",
    "    \n",
    "    return segment\n",
    "\n",
    "# Delete segments that are too short\n",
    "print('Calculating segment length:')\n",
    "num_before = flights.segment_id.nunique()\n",
    "segment_size = flights.groupby('segment_id').progress_apply(lambda f: f.time.shape[0])\n",
    "segments_tooshort = segment_size[segment_size < 2*RMEAN_LENG]\n",
    "flights = flights[~flights.segment_id.isin(segments_tooshort.index)].reset_index(drop=True)\n",
    "print(f'Removed {num_before-flights.segment_id.nunique()}/{num_before} segments that are too short')\n",
    "print(' ')\n",
    "\n",
    "# Calculate the running mean altitude and the smoothed vertical velocity\n",
    "print('Calculating smoothed altitude and vertical velocity:')\n",
    "flights = flights.groupby('segment_id').progress_apply(altitude_runningmean).reset_index(drop=True)\n",
    "\n",
    "# Tag times where the smoothed vertical velocity exceeds VERTVEL_THRESH\n",
    "# Ascending and descending instances are flagged seperately\n",
    "temp_dt = VERTVEL_THRESH_DT/pd.Timedelta(1,'seconds')\n",
    "VERTVEL_THRESH = DZ_THRESH/temp_dt\n",
    "flights['vertvel_flag'] = 0\n",
    "flights.loc[flights.w_smooth > VERTVEL_THRESH, 'vertvel_flag'] = 1\n",
    "flights.loc[flights.w_smooth < -VERTVEL_THRESH, 'vertvel_flag'] = -1\n",
    "\n",
    "# Delete w_smooth\n",
    "flights = flights.drop(columns=['w_smooth'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interrogate the flagged times, looking for intervals when the altitude changed more than DZ_THRESH\n",
    "\n",
    "If it does, flag the data within +/-VERTVEL_THRESH_DT of the interval for deletion.\n",
    "\n",
    "The idea here is to detect large (> ~1km) secular changes in altitude over short (hours) time intervals and delete them (without accidentally deleting large amplitude GWs). This usually works, but sometimes suspicious data aren't deleted because the altitude change isn't large enough. These data are flagged, so if they are included in a GW packet, that packet can be looked at to see if it makes sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flagging times when the smoothed altitude changes too much and splitting data into segments\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab1b85b0dfdb40e19d0d25cb229ff6fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1657 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of segments before: 1657; number of segments now: 1651\n",
      " \n",
      "Calculating segment length:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bf2c009630146b38d76d5371a140a60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1651 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0/1651 segments that are too short\n",
      " \n",
      "Calculating segment mean altitude:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d5469f68acf42878b5506aec7ea0197",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1651 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0/1651 segments that are too low\n",
      " \n",
      "Of original 986795 data points, 60.6904169559027% is retained\n"
     ]
    }
   ],
   "source": [
    "def flag_largedz(segment):\n",
    "    \n",
    "    # Create a counter so that the segment ID is incremented across the flights, creating unique segment IDs\n",
    "    if \"counter\" not in flag_largedz.__dict__:\n",
    "        flag_largedz.counter = 0\n",
    "    \n",
    "    # Create data \"chunks\" that are identified by their vertvel_flag value\n",
    "    # (an ascending chunk is followed by a neutral chunk, is followed by a descending chunk, etc.)\n",
    "    segment['chunk_id'] = (segment.vertvel_flag.diff() != 0).astype(int).cumsum()\n",
    "    chunk_ids = segment.chunk_id.unique()\n",
    "    n_chunks = segment.chunk_id.nunique()\n",
    "    \n",
    "    # Check if alt_rmean changed too much across the chunk\n",
    "    segment['flagged'] = 0\n",
    "    for i in np.arange(n_chunks):\n",
    "        temp = segment[segment.chunk_id == chunk_ids[i]]\n",
    "        if temp.vertvel_flag.iloc[0] != 0: # only analyze flagged chunks\n",
    "            # Include the interval VERTVEL_THRESH_DT/2 before and after the chunk\n",
    "            t_start = temp.time.iloc[0] - VERTVEL_THRESH_DT/2\n",
    "            t_stop = temp.time.iloc[-1] + VERTVEL_THRESH_DT/2\n",
    "            temp = segment[segment.time >= t_start]\n",
    "            temp = temp[temp.time < t_stop]\n",
    "            if temp.alt_rmean.max() - temp.alt_rmean.min() > DZ_THRESH:\n",
    "                segment.loc[segment.index.isin(temp.index),'flagged'] = 1\n",
    "                \n",
    "    # Each time maneuvering stops, a new segment begins:\n",
    "    segment['segment_id_new'] = (segment.flagged.diff() == -1).astype(int).cumsum()\n",
    "    n_segments = segment.segment_id_new.max() + 1 # the segments start at zero\n",
    "    \n",
    "    # Delete any data points where maneuvering is happening\n",
    "    segment = segment[segment.flagged==0]\n",
    "    \n",
    "    # Apply the counter and increment it\n",
    "    segment.segment_id_new = segment.segment_id_new + flag_largedz.counter\n",
    "    flag_largedz.counter = flag_largedz.counter + n_segments\n",
    "    \n",
    "    return segment\n",
    "\n",
    "\n",
    "# Flag chunks of data where the smoothed dz is too big\n",
    "num_before = flights.segment_id.nunique()\n",
    "print('Flagging times when the smoothed altitude changes too much and splitting data into segments')\n",
    "flights = flights.groupby('segment_id').progress_apply(flag_largedz).reset_index(drop=True)\n",
    "flights = flights.drop(columns=['segment_id'])\n",
    "flights = flights.rename(columns={'segment_id_new': 'segment_id'})\n",
    "#segments = segments.groupby('segment_id').progress_apply(flag_largedz).reset_index(drop=True)\n",
    "#segments = segments.drop(columns=['segment_id'])\n",
    "#segments = segments.rename(columns={'segment_id_new': 'segment_id'})\n",
    "print(f'Number of segments before: {num_before}; number of segments now: {flights.segment_id.nunique()}')\n",
    "print(' ')\n",
    "\n",
    "# Delete segments that are too short\n",
    "print('Calculating segment length:')\n",
    "num_before = flights.segment_id.nunique()\n",
    "segment_length = flights.groupby('segment_id').progress_apply(lambda f: f.time.iloc[-1] - f.time.iloc[0])\n",
    "segments_tooshort = segment_length[segment_length < MIN_SEG_LEN]\n",
    "flights = flights[~flights.segment_id.isin(segments_tooshort.index)].reset_index(drop=True)\n",
    "print(f'Removed {num_before-flights.segment_id.nunique()}/{num_before} segments that are too short')\n",
    "print(' ')\n",
    "\n",
    "# Delete segments with mean altitudes that are too low\n",
    "print('Calculating segment mean altitude:')\n",
    "num_before = flights.segment_id.nunique()\n",
    "segment_alt = flights.groupby('segment_id').progress_apply(lambda f: f.altitude.mean())\n",
    "segments_toolow = segment_alt[segment_alt < SEG_MIN_ALT]\n",
    "flights = flights[~flights.segment_id.isin(segments_toolow.index)].reset_index(drop=True)\n",
    "print(f'Removed {num_before-flights.segment_id.nunique()}/{num_before} segments that are too low')\n",
    "print(' ')\n",
    "\n",
    "# How much data is left over?\n",
    "print(f'Of original {n_data_orig} data points, {100*flights.shape[0]/n_data_orig}% are retained')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete data fields that are unneeded after this\n",
    "flights = flights.drop(columns=['maneuvering','alt_rmean','chunk_id','flagged'])\n",
    "flights = flights.rename(columns={'vertvel_flag': 'suspicious_motion'})\n",
    "\n",
    "flights.to_feather('temp_data/2_segments_2014.feather')\n",
    "flights.time.min(), flights.time.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the years are done separately and need to be combined, make sure the segment IDs are unique\n",
    "temp1 = pd.read_feather('temp_data/3_segments_2011-2013.feather')\n",
    "temp2 = pd.read_feather('temp_data/3_segments_2014.feather')\n",
    "temp3 = pd.read_feather('temp_data/3_segments_2015.feather')\n",
    "temp4 = pd.read_feather('temp_data/3_segments_2016.feather')\n",
    "temp5 = pd.read_feather('temp_data/3_segments_2017.feather')\n",
    "temp6 = pd.read_feather('temp_data/3_segments_2018.feather')\n",
    "\n",
    "# Increment the segment IDs from one file to another, so they are still unique\n",
    "temp2.segment_id = temp2.segment_id + temp1.segment_id.max() + 1\n",
    "temp3.segment_id = temp3.segment_id + temp2.segment_id.max() + 1\n",
    "temp4.segment_id = temp4.segment_id + temp3.segment_id.max() + 1\n",
    "temp5.segment_id = temp5.segment_id + temp4.segment_id.max() + 1\n",
    "temp6.segment_id = temp6.segment_id + temp5.segment_id.max() + 1\n",
    "\n",
    "frames = [temp1, temp2, temp3, temp4, temp5, temp6]\n",
    "flights = pd.concat(frames, ignore_index = True)\n",
    "\n",
    "flights.to_feather('temp_data/3_segments_cosmic_2011-2018.feather')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
